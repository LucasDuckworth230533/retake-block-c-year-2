{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f99137f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Beheerder\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Beheerder\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da40c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix utf-8 error\n",
    "test_df = pd.read_csv(\"../datasets/group 2_url1.csv\", encoding='ISO-8859-1')\n",
    "train_df = pd.read_csv(\"../datasets/final_dataset.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "# Keep only the necessary columns in test_df (Sentence, Emotion)\n",
    "test_df = test_df[['Sentence', 'Emotion']]\n",
    "# Keep only the necessary columns in train_df (Sentence, Core_Pipeline_Emotion)\n",
    "train_df = train_df[['Sentence', 'Core_Pipeline_Emotion']]\n",
    "\n",
    "# Remove rows with NaN values in the 'Emotion' column of test_df\n",
    "test_df = test_df.dropna(subset=['Emotion'])\n",
    "\n",
    "# Create mapping dictionary for emotions for test_df \n",
    "emotion_mapping = {\n",
    "    'anger': ['disapproval', 'annoyance'],\n",
    "    'fear': ['fear', 'nervousness'],\n",
    "    'happiness': ['admiration', 'excitement', 'relief', 'amusement', 'optimism',\n",
    "            'approval', 'gratitude', 'caring', 'joy', 'pride', 'desire', 'love'],\n",
    "    'sadness': ['sadness', 'embarrassment', 'disappointment', 'remorse'],\n",
    "    'surprise': ['curiosity', 'realization', 'confusion', 'surprise'],\n",
    "    'neutral': ['nan', 'neutral'],\n",
    "    'disgust': ['disgust']\n",
    "}\n",
    "\n",
    "# Apply the mapping to test_df\n",
    "def map_emotion(row):\n",
    "    for emotion, synonyms in emotion_mapping.items():\n",
    "        if row['Emotion'] in synonyms:\n",
    "            return emotion\n",
    "test_df['Emotion'] = test_df.apply(map_emotion, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "108a841e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Sentence    Emotion\n",
      "1               van jullie het eiland weer verlaten.    neutral\n",
      "2  Maar zie het als een compliment, want eigenlij...  happiness\n",
      "3  zien als de grootste bedreiging voor hun relatie.       fear\n",
      "4                    OkÃ©, hier zijn ze, de koppels!  happiness\n",
      "5  De koppels zien elkaar een laatste keer terug,...    sadness\n",
      "                                            Sentence Core_Pipeline_Emotion\n",
      "0        Heb je een vriend? Nee, ik heb geen vriend.               neutral\n",
      "1  Wil je een single? Ja, ik ben al vier jaar sin...               neutral\n",
      "2                            Oh. Maar vind je dat...               neutral\n",
      "3  Bewust, niet bewust. Ik vind het goed dat het is.              surprise\n",
      "4            Je gaat er ook niet naar opzoeken? Nee.               neutral\n",
      "Unique emotions in test_df: ['neutral' 'happiness' 'fear' 'sadness' 'surprise' 'anger' 'disgust']\n",
      "Unique emotions in train_df: ['neutral' 'surprise' 'sadness' 'happiness' 'disgust' 'fear' 'anger']\n",
      "Number of emotions in test_df:\n",
      "Emotion\n",
      "neutral      256\n",
      "happiness    250\n",
      "surprise     147\n",
      "anger         47\n",
      "sadness       31\n",
      "fear          17\n",
      "disgust        2\n",
      "Name: count, dtype: int64\n",
      "Number of emotions in train_df:\n",
      "Core_Pipeline_Emotion\n",
      "neutral      1576\n",
      "happiness    1145\n",
      "surprise      425\n",
      "sadness       370\n",
      "fear          209\n",
      "disgust        93\n",
      "anger          37\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_df.head())\n",
    "print(train_df.head())\n",
    "\n",
    "# Print all the unique emotions in test_df\n",
    "print(\"Unique emotions in test_df:\", test_df['Emotion'].unique())\n",
    "# Print all the unique emotions in train_df\n",
    "print(\"Unique emotions in train_df:\", train_df['Core_Pipeline_Emotion'].unique())\n",
    "\n",
    "# Print the number of emotions for each unique emotions in test_df\n",
    "print(\"Number of emotions in test_df:\")\n",
    "print(test_df['Emotion'].value_counts())\n",
    "# Print the number of emotions for each unique emotions in train_df\n",
    "print(\"Number of emotions in train_df:\")\n",
    "print(train_df['Core_Pipeline_Emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e79424c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define underrepresented emotions with their desired augmentation counts\n",
    "augmentation_targets = {\n",
    "    'surprise': 3,\n",
    "    'anger': 15,\n",
    "    'fear': 6,\n",
    "    'sadness': 3,\n",
    "    'disgust': 8\n",
    "}\n",
    "\n",
    "# Function to replace words with Dutch synonyms\n",
    "def augment_with_synonyms(sentence, max_replacements=2):\n",
    "    words = sentence.split()\n",
    "    augmented = words[:]\n",
    "    indices = [i for i, word in enumerate(words) if wordnet.synsets(word, lang='nld')]\n",
    "\n",
    "    if not indices:\n",
    "        return sentence\n",
    "\n",
    "    random.shuffle(indices)\n",
    "    for i in indices[:min(max_replacements, len(indices))]:\n",
    "        syns = wordnet.synsets(words[i], lang='nld')\n",
    "        if syns:\n",
    "            lemmas = syns[0].lemma_names(lang='nld')\n",
    "            if lemmas:\n",
    "                augmented[i] = random.choice(lemmas).replace('_', ' ')\n",
    "\n",
    "    return ' '.join(augmented)\n",
    "\n",
    "# Augment the underrepresented emotions\n",
    "augmented_rows = []\n",
    "for _, row in train_df.iterrows():\n",
    "    emotion = row['Core_Pipeline_Emotion']\n",
    "    sentence = row['Sentence']\n",
    "\n",
    "    n_augments = augmentation_targets.get(emotion, 0)\n",
    "    for _ in range(n_augments):\n",
    "        augmented_rows.append({\n",
    "            'Corrected Sentence': augment_with_synonyms(sentence),\n",
    "            'Corrected_Emotion': emotion\n",
    "        })\n",
    "\n",
    "# Combine original and augmented data\n",
    "df_aug = pd.DataFrame(augmented_rows)\n",
    "df_combined = pd.concat([train_df, df_aug], ignore_index=True)\n",
    "\n",
    "# Map emotion labels to indices\n",
    "class_names = ['neutral', 'sadness', 'happiness', 'surprise', 'fear', 'anger', 'disgust']\n",
    "df_combined = df_combined[df_combined['Corrected_Emotion'].isin(class_names)]\n",
    "df_combined['label'] = df_combined['Corrected_Emotion'].map(lambda x: class_names.index(x))\n",
    "\n",
    "\n",
    "# Create training/validation split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df_combined['Corrected Sentence'].tolist(),\n",
    "    df_combined['label'].tolist(),\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d66766f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique emotions in full_df: ['surprise' 'sadness' 'disgust' 'fear' 'anger' 'neutral' 'happiness']\n",
      "Number of emotions in full_df:\n",
      "Core_Pipeline_Emotion\n",
      "surprise     1700\n",
      "neutral      1576\n",
      "sadness      1480\n",
      "fear         1463\n",
      "happiness    1145\n",
      "disgust       837\n",
      "anger         592\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Make sure both dataframes have the same structure\n",
    "df_combined['Sentence'] = df_combined['Corrected Sentence']\n",
    "df_combined['Core_Pipeline_Emotion'] = df_combined['Corrected_Emotion']\n",
    "df_combined = df_combined.drop(columns=['Corrected Sentence', 'Corrected_Emotion', 'label'])\n",
    "\n",
    "# Let's assume df_original has columns 'Sentence' and 'Emotion'\n",
    "train_df = train_df.rename(columns={'Emotion': 'Core_Pipeline_Emotion'})\n",
    "\n",
    "# Combine both datasets\n",
    "full_df = pd.concat([df_combined[['Sentence', 'Core_Pipeline_Emotion']],\n",
    "                     train_df[['Sentence', 'Core_Pipeline_Emotion']]],\n",
    "                    ignore_index=True)\n",
    "\n",
    "# Print summary\n",
    "print(\"Unique emotions in full_df:\", full_df['Core_Pipeline_Emotion'].unique())\n",
    "print(\"Number of emotions in full_df:\")\n",
    "print(full_df['Core_Pipeline_Emotion'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a948e0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bewust, kram bewust. ik vind het goed dat het is.</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bewust, niet bewust. hooghartigheid vind het h...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bewust, kram bewust. hooghartigheid vind het g...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Er staat wel houden open, bezwaar het is niet.</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Er staat wel houden open, maar het is niet.</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence   Emotion\n",
       "0  Bewust, kram bewust. ik vind het goed dat het is.  surprise\n",
       "1  Bewust, niet bewust. hooghartigheid vind het h...  surprise\n",
       "2  Bewust, kram bewust. hooghartigheid vind het g...  surprise\n",
       "3     Er staat wel houden open, bezwaar het is niet.   sadness\n",
       "4        Er staat wel houden open, maar het is niet.   sadness"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename core pipeline emotion to emotion\n",
    "full_df = full_df.rename(columns={'Core_Pipeline_Emotion': 'Emotion'})\n",
    "\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5517d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df_combined DataFrame to a CSV file (Training_dataset.csv)\n",
    "#full_df.to_csv('Training_dataset.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f59a5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test_df DataFrame to a CSV file (Test_dataset.csv)\n",
    "# test_df.to_csv('Test_dataset.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e7202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate sentences in df_combined:\n",
      "                                               Sentence    Emotion\n",
      "6                                          agrafe doen.    disgust\n",
      "7                                          agrafe doen.    disgust\n",
      "8                                            niet doen.    disgust\n",
      "9                                          agrafe doen.    disgust\n",
      "10                                           niet doen.    disgust\n",
      "...                                                 ...        ...\n",
      "8788                                         Top. Mooi.  happiness\n",
      "8789  Jullie gaan naar de cocoonruimte. Dat is de gr...    neutral\n",
      "8790          En jullie leren elkaar daar beter kennen.  happiness\n",
      "8791              De barbie room. Hij heeft wel koffer.   surprise\n",
      "8792                     Ja. Hebben jullie geen koffer?    sadness\n",
      "\n",
      "[4141 rows x 2 columns]\n",
      "Duplicate sentences in test_df:\n",
      "                                              Sentence    Emotion\n",
      "11                                                 Zo.    neutral\n",
      "47                                                 Ja.    neutral\n",
      "48                                             VoilÃ .    neutral\n",
      "56                                               OkÃ©.  happiness\n",
      "65                                               OkÃ©.  happiness\n",
      "84                                                 Zo.    neutral\n",
      "107                                                Ja.    neutral\n",
      "129                                               Nee.      anger\n",
      "130                                               Nee.      anger\n",
      "131                                                Ja.    neutral\n",
      "254                    Ik heb er echt helemaal zin in.  happiness\n",
      "255                    Ik heb er echt helemaal zin in.  happiness\n",
      "278                                         Zo is het.    neutral\n",
      "279                                         Zo is het.    neutral\n",
      "319             Tim, je gaat vandaag met Iene op stap.  happiness\n",
      "322             Tim, je gaat vandaag met Iene op stap.  happiness\n",
      "328                                          Go, girl.    neutral\n",
      "329                                          Go, girl.    neutral\n",
      "335  Dames, wie gaat James vandaag de dag van zijn ...  happiness\n",
      "337  Dames, wie gaat James vandaag de dag van zijn ...  happiness\n",
      "381                                      Sven of Rick.    neutral\n",
      "382                                      Sven of Rick.    neutral\n",
      "390                                             Allee.    neutral\n",
      "399                                               Nee.    neutral\n",
      "403                                                Ja.    neutral\n",
      "418                                             Allee.    neutral\n",
      "438                                               Nee.    neutral\n",
      "476                                               Nee.    neutral\n",
      "478                                                Ja.    neutral\n",
      "479                                                Ja.    neutral\n",
      "535                                               Nee.    neutral\n",
      "544                                                Ja.    neutral\n",
      "567                                               Nee.    neutral\n",
      "606                          Ik ga nooit meer op date.    sadness\n",
      "607                          Ik ga nooit meer op date.    sadness\n",
      "708                                We hebben nog even.  happiness\n",
      "709                 We zijn hier al maar de derde dag.    neutral\n",
      "710                                We hebben nog even.  happiness\n",
      "711                 We zijn hier al maar de derde dag.    neutral\n",
      "718                                    Dat is plezant.  happiness\n",
      "719                                    Dat is plezant.  happiness\n",
      "720                                    Dat is plezant.  happiness\n",
      "742                                            VoilÃ .    neutral\n",
      "Common sentences found in both df_combined and test_df:\n",
      "{'Oh my God.', 'Sorry.', 'Zo.', 'Kijk.', 'Ja, zeker.', 'Nee.', 'Allee.', 'Dank je wel.', 'Ja?', 'Ja!', 'Ik weet het niet.', 'Dank je.', 'Helaas.', 'Maar...', 'All right.', 'Ja.', 'Ja? Ja.'}\n"
     ]
    }
   ],
   "source": [
    "# Show duplicate sentences in df_combined and test_df\n",
    "duplicates_combined = full_df[full_df.duplicated(subset=['Sentence'], keep=False)]\n",
    "duplicates_test = test_df[test_df.duplicated(subset=['Sentence'], keep=False)]\n",
    "print(\"Duplicate sentences in df_combined:\")\n",
    "print(duplicates_combined)\n",
    "print(\"Duplicate sentences in test_df:\")\n",
    "print(duplicates_test)\n",
    "\n",
    "# Show if there are any sentences both in df_combined and test_df\n",
    "common_sentences = set(full_df['Sentence']).intersection(set(test_df['Sentence']))\n",
    "if common_sentences:\n",
    "    print(\"Common sentences found in both df_combined and test_df:\")\n",
    "    print(common_sentences)\n",
    "\n",
    "# remove duplicates from full_df\n",
    "full_df = full_df.drop_duplicates(subset=['Sentence'])\n",
    "# remove duplicates from test_df\n",
    "test_df = test_df.drop_duplicates(subset=['Sentence'])\n",
    "\n",
    "#remove the common sentences from train_df\n",
    "\n",
    "full_df = full_df[~full_df['Sentence'].isin(test_df['Sentence'])]\n",
    "\n",
    "# Save the final DataFrames to CSV files\n",
    "#full_df.to_csv('Training_dataset.csv', index=False, encoding='utf-8')\n",
    "#test_df.to_csv('Test_dataset.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "block_c_Y2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
